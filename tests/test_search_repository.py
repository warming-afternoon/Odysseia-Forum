# tests/test_search_repository.py

import pytest
import pytest_asyncio
from typing import AsyncGenerator, List, Set
from datetime import datetime

from sqlalchemy.pool import StaticPool
from sqlalchemy import event
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
from sqlmodel import SQLModel, text, delete

import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../src")))

from shared.fts5_tokenizer import register_jieba_tokenizer
from shared.models.thread import Thread
from search.search_service import SearchService
from search.qo.thread_search import ThreadSearchQuery
from core.tag_service import TagService

# ä½¿ç”¨å†…å­˜æ•°æ®åº“è¿›è¡Œæµ‹è¯•
TEST_DATABASE_URL = "sqlite+aiosqlite:///:memory:"


@pytest_asyncio.fixture(scope="module")
async def db_session_factory() -> AsyncGenerator[
    async_sessionmaker[AsyncSession], None
]:
    """
    åˆ›å»ºä¸€ä¸ªæ¨¡å—çº§åˆ«çš„æ•°æ®åº“å¼•æ“å’Œä¼šè¯å·¥å‚ã€‚
    """
    engine = create_async_engine(
        TEST_DATABASE_URL,
        poolclass=StaticPool,
        connect_args={"check_same_thread": False},
    )

    @event.listens_for(engine.sync_engine, "connect")
    def on_connect(dbapi_conn, connection_record):
        try:
            aiosqlite_conn = dbapi_conn._connection
            underlying_sqlite3_conn = aiosqlite_conn._conn
            register_jieba_tokenizer(underlying_sqlite3_conn)
        except Exception as e:
            print(f"åœ¨æ–°è¿æ¥ä¸Šæ³¨å†Œåˆ†è¯å™¨å¤±è´¥: {e}")
            raise

    # æ•°æ®åº“åˆå§‹åŒ–é€»è¾‘ï¼ˆåŒ…æ‹¬FTSè¡¨å’Œè§¦å‘å™¨ï¼‰
    async with engine.begin() as conn:
        await conn.run_sync(SQLModel.metadata.create_all)
        await conn.execute(
            text(
                """
                CREATE VIRTUAL TABLE IF NOT EXISTS thread_fts USING fts5(
                    title,
                    first_message_excerpt,
                    content='thread',
                    content_rowid='id',
                    tokenize = 'jieba'
                );
                """
            )
        )
        await conn.execute(
            text(
                """
                CREATE TRIGGER IF NOT EXISTS thread_after_insert
                AFTER INSERT ON thread BEGIN
                    INSERT INTO thread_fts(rowid, title, first_message_excerpt)
                    VALUES (new.id, new.title, new.first_message_excerpt);
                END;
                """
            )
        )
        await conn.execute(
            text(
                """
                CREATE TRIGGER IF NOT EXISTS thread_after_delete
                AFTER DELETE ON thread BEGIN
                    INSERT INTO thread_fts(thread_fts, rowid, title, first_message_excerpt)
                    VALUES ('delete', old.id, old.title, old.first_message_excerpt);
                END;
                """
            )
        )
        await conn.execute(
            text(
                """
                CREATE TRIGGER IF NOT EXISTS thread_after_update
                AFTER UPDATE ON thread BEGIN
                    INSERT INTO thread_fts(thread_fts, rowid, title, first_message_excerpt)
                    VALUES ('delete', old.id, old.title, old.first_message_excerpt);
                    INSERT INTO thread_fts(rowid, title, first_message_excerpt)
                    VALUES (new.id, new.title, new.first_message_excerpt);
                END;
                """
            )
        )

    factory = async_sessionmaker(engine, expire_on_commit=False, class_=AsyncSession)
    yield factory

    await engine.dispose()


@pytest_asyncio.fixture(scope="function")
async def seeded_db_session(
    db_session_factory: async_sessionmaker[AsyncSession],
) -> AsyncGenerator[AsyncSession, None]:
    """
    æä¾›ä¸€ä¸ªå¡«å……äº†æµ‹è¯•æ•°æ®çš„æ•°æ®åº“ä¼šè¯ã€‚
    ä½¿ç”¨ function çº§åˆ«ç¡®ä¿æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹éƒ½åœ¨ä¸€ä¸ªå¹²å‡€çš„æ•°æ®ç¯å¢ƒä¸­è¿è¡Œã€‚
    """
    async with db_session_factory() as session:
        # æµ‹è¯•æ•°æ®
        threads_to_create = [
            Thread(
                channel_id=1,
                thread_id=101,
                title="å…³äºç™¾åˆç ´åçš„è®¨è®º",
                author_id=1,
                created_at=datetime.now(),
            ),
            Thread(
                channel_id=1,
                thread_id=102,
                title="ğŸˆ²ç™¾åˆç ´å",
                author_id=2,
                created_at=datetime.now(),
            ),
            Thread(
                channel_id=1,
                thread_id=103,
                title="å°è¯´æ¨è",
                author_id=3,
                created_at=datetime.now(),
            ),
            Thread(
                channel_id=1,
                thread_id=104,
                title="ç¦ï¼šè¯·å‹¿è®¨è®ºç™¾åˆç ´åè¯é¢˜",
                author_id=4,
                created_at=datetime.now(),
            ),
            Thread(
                channel_id=1,
                thread_id=105,
                title="çº¯çˆ±å°è¯´åˆ†äº«",
                author_id=5,
                created_at=datetime.now(),
            ),
        ]
        session.add_all(threads_to_create)
        await session.commit()

        yield session

        # åœ¨æ¯ä¸ªæµ‹è¯•ç»“æŸåæ¸…ç†æ•°æ®ï¼Œç¡®ä¿æµ‹è¯•ä¹‹é—´çš„ç‹¬ç«‹æ€§
        await session.execute(delete(Thread))
        await session.commit()


# --- å‚æ•°åŒ–æµ‹è¯• ---
@pytest.mark.parametrize(
    "test_id, exclude_keywords, exemption_markers, expected_count, expected_present, expected_absent",
    [
        (
            "1_full_word_with_exemption",
            "ç™¾åˆç ´å",
            ["ç¦", "ğŸˆ²"],
            4,
            {"ğŸˆ²ç™¾åˆç ´å", "ç¦ï¼šè¯·å‹¿è®¨è®ºç™¾åˆç ´åè¯é¢˜", "å°è¯´æ¨è", "çº¯çˆ±å°è¯´åˆ†äº«"},
            {"å…³äºç™¾åˆç ´åçš„è®¨è®º"},
        ),
        (
            "2_prefix_with_exemption",
            "ç™¾åˆç ´",
            ["ç¦", "ğŸˆ²"],
            4,
            {"ğŸˆ²ç™¾åˆç ´å", "ç¦ï¼šè¯·å‹¿è®¨è®ºç™¾åˆç ´åè¯é¢˜", "å°è¯´æ¨è", "çº¯çˆ±å°è¯´åˆ†äº«"},
            {"å…³äºç™¾åˆç ´åçš„è®¨è®º"},
        ),
        (
            "3_general_prefix_with_exemption",
            "ç™¾åˆ",
            ["ç¦", "ğŸˆ²"],
            4,
            {"ğŸˆ²ç™¾åˆç ´å", "ç¦ï¼šè¯·å‹¿è®¨è®ºç™¾åˆç ´åè¯é¢˜", "å°è¯´æ¨è", "çº¯çˆ±å°è¯´åˆ†äº«"},
            {"å…³äºç™¾åˆç ´åçš„è®¨è®º"},
        ),
        (
            "4_full_word_no_exemption",
            "ç™¾åˆç ´å",
            [],
            2,
            {"å°è¯´æ¨è", "çº¯çˆ±å°è¯´åˆ†äº«"},
            {"å…³äºç™¾åˆç ´åçš„è®¨è®º", "ğŸˆ²ç™¾åˆç ´å", "ç¦ï¼šè¯·å‹¿è®¨è®ºç™¾åˆç ´åè¯é¢˜"},
        ),
        (
            "5_prefix_no_exemption",
            "ç™¾åˆç ´",
            [],
            2,
            {"å°è¯´æ¨è", "çº¯çˆ±å°è¯´åˆ†äº«"},
            {"å…³äºç™¾åˆç ´åçš„è®¨è®º", "ğŸˆ²ç™¾åˆç ´å", "ç¦ï¼šè¯·å‹¿è®¨è®ºç™¾åˆç ´åè¯é¢˜"},
        ),
        (
            "6_multiple_keywords_or_logic",
            "ç™¾åˆç ´å å°è¯´",
            [],
            0,
            set(),
            {
                "å…³äºç™¾åˆç ´åçš„è®¨è®º",
                "ğŸˆ²ç™¾åˆç ´å",
                "ç¦ï¼šè¯·å‹¿è®¨è®ºç™¾åˆç ´åè¯é¢˜",
                "å°è¯´æ¨è",
                "çº¯çˆ±å°è¯´åˆ†äº«",
            },
        ),
        (
            "7_multiple_keywords_with_exemption",
            "ç™¾åˆç ´å çº¯çˆ±",
            ["ç¦", "ğŸˆ²"],
            3,
            {"ğŸˆ²ç™¾åˆç ´å", "ç¦ï¼šè¯·å‹¿è®¨è®ºç™¾åˆç ´åè¯é¢˜", "å°è¯´æ¨è"},
            {"å…³äºç™¾åˆç ´åçš„è®¨è®º", "çº¯çˆ±å°è¯´åˆ†äº«"},
        ),
    ],
)
@pytest.mark.asyncio
async def test_search_exclusion_scenarios(
    seeded_db_session: AsyncSession,
    db_session_factory: async_sessionmaker[AsyncSession],
    test_id: str,
    exclude_keywords: str,
    exemption_markers: List[str],
    expected_count: int,
    expected_present: Set[str],
    expected_absent: Set[str],
):
    """
    å¯¹åé€‰å…³é”®è¯çš„å„ç§åœºæ™¯è¿›è¡Œå‚æ•°åŒ–æµ‹è¯•ã€‚
    """
    # 1. å‡†å¤‡
    tag_service = TagService(session_factory=db_session_factory)
    await tag_service.build_cache()
    repo = SearchService(session=seeded_db_session, tag_service=tag_service)

    # 2. æ„å»ºæŸ¥è¯¢
    query = ThreadSearchQuery(
        exclude_keywords=exclude_keywords,
        exclude_keyword_exemption_markers=exemption_markers,
    )

    # 3. æ‰§è¡Œæœç´¢
    threads, total_threads = await repo.search_threads_with_count(
        query=query,
        offset=0,
        limit=10,
        total_display_count=1000,
        exploration_factor=1.414,
        strength_weight=10.0,
    )

    # 4. æ–­è¨€ç»“æœ
    returned_titles = {t.title for t in threads}

    print(f"--- è¿è¡Œæµ‹è¯•: {test_id} ---")
    print(f"æ’é™¤å…³é”®è¯: '{exclude_keywords}'")
    print(f"è¿”å›çš„æ ‡é¢˜: {returned_titles}")
    print(f"é¢„æœŸæ•°é‡: {expected_count}, å®é™…: {total_threads}")
    print(f"é¢„æœŸå­˜åœ¨: {expected_present}")
    print(f"é¢„æœŸä¸å­˜åœ¨: {expected_absent}")

    assert total_threads == expected_count, f"æµ‹è¯• '{test_id}' å¤±è´¥ï¼šæ€»æ•°ä¸åŒ¹é…"
    assert returned_titles.issuperset(expected_present), (
        f"æµ‹è¯• '{test_id}' å¤±è´¥ï¼šéƒ¨åˆ†é¢„æœŸç»“æœç¼ºå¤±"
    )
    assert not returned_titles.intersection(expected_absent), (
        f"æµ‹è¯• '{test_id}' å¤±è´¥ï¼šè¿”å›äº†ä¸åº”å‡ºç°çš„ç»“æœ"
    )
